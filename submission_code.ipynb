{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook generates a 13 weeks long forecast of sales data for each product as part of the VN1 challenge. The underlying model \n",
    "used for the predictions is a LGBM with an Tweedie objective function. The predictions are generated using a recursive approach, \n",
    "where the model predicts the sales for the next week and then uses these values to generate the predictions for the next time period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functions_for_participants import *\n",
    "import lightgbm as lgb\n",
    "import tqdm as tq\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore Warnings\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Sales Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Sales Data for both Phases and combine them into one single DataFrane\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales = pd.read_csv(\"Phase 0 - Sales.csv\")\n",
    "df_sales_1 = pd.read_csv(\"Phase 1 - Sales.csv\")\n",
    "df_sales = pd.concat([df_sales, df_sales_1], axis=1)\n",
    "# Drop duplicate columns\n",
    "df_sales = df_sales.loc[:, ~df_sales.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the sales data into a Sales and Date columns\n",
    "param = \"Sales\" \n",
    "list_columns = list(df_sales.columns)\n",
    "list_dates_columns = list_columns [3:]\n",
    "df_sales = df_sales.melt(id_vars=['Client', 'Warehouse', 'Product'], var_name='Date', value_vars=list_dates_columns, value_name=param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Client</th>\n",
       "      <th>Warehouse</th>\n",
       "      <th>Product</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>367</td>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>639</td>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>655</td>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1149</td>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1485</td>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754694</th>\n",
       "      <td>46</td>\n",
       "      <td>318</td>\n",
       "      <td>13485</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754695</th>\n",
       "      <td>46</td>\n",
       "      <td>318</td>\n",
       "      <td>13582</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754696</th>\n",
       "      <td>46</td>\n",
       "      <td>318</td>\n",
       "      <td>13691</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754697</th>\n",
       "      <td>46</td>\n",
       "      <td>318</td>\n",
       "      <td>13946</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754698</th>\n",
       "      <td>46</td>\n",
       "      <td>318</td>\n",
       "      <td>14294</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2754699 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Client  Warehouse  Product        Date  Sales\n",
       "0             0          1      367  2020-07-06    7.0\n",
       "1             0          1      639  2020-07-06    0.0\n",
       "2             0          1      655  2020-07-06   21.0\n",
       "3             0          1     1149  2020-07-06    7.0\n",
       "4             0          1     1485  2020-07-06    0.0\n",
       "...         ...        ...      ...         ...    ...\n",
       "2754694      46        318    13485  2024-01-01    0.0\n",
       "2754695      46        318    13582  2024-01-01   67.0\n",
       "2754696      46        318    13691  2024-01-01    2.0\n",
       "2754697      46        318    13946  2024-01-01    0.0\n",
       "2754698      46        318    14294  2024-01-01    3.0\n",
       "\n",
       "[2754699 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the data types for the columns to optimize memory\n",
    "dtype_dict = {\n",
    "    'Client': 'int32',\n",
    "    'Warehouse': 'int32',\n",
    "    'Product': 'int32',\n",
    "    \"Sales\": \"float32\",\n",
    "}\n",
    "\n",
    "# Convert the columns to the specified data types\n",
    "for col in df_sales.columns:\n",
    "    if col in dtype_dict.keys():\n",
    "        df_sales[col] = df_sales[col].astype(dtype_dict[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derive Summary Statistics for Client, Warehouse, Product and Date Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Section derives summary statistics(Sum,Mean,Std,Median) for the above mentioned columns. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of grouping columns\n",
    "elements = ['Client', 'Warehouse', 'Product',\"Date\"]\n",
    "\n",
    "relationship_dict = {}\n",
    "\n",
    "def combine_sales_data(df_combined, elements, relationship_dict):\n",
    "    elements_dict = {}\n",
    "    # Convert Date to datetime type in both DataFrames\n",
    "    df_combined['Date'] = pd.to_datetime(df_combined['Date'])\n",
    "    \n",
    "    for element in elements:\n",
    "        # Determine the columns to group by\n",
    "        groupby_columns = [element] if element == 'Date' else [element, 'Date']\n",
    "        \n",
    "        # Perform group by on each combination along with 'Date'\n",
    "        df_grouped = df_combined[groupby_columns + [\"Sales\"]].groupby(groupby_columns).agg(['sum', \"std\",\"mean\",\"median\"]).reset_index()\n",
    "        \n",
    "        # Remove multi-level index and rename columns\n",
    "        df_grouped.columns = [\n",
    "            f'total_{col[0]}_{col[1]}_by_{element}'.lower() if col[0] not in [element, 'Date'] else col[0]\n",
    "            for col in df_grouped.columns\n",
    "        ]\n",
    "        columns = [col for col in df_grouped.columns if col not in [element, 'Date']]\n",
    "        # print(columns)\n",
    "        for column in columns:\n",
    "            elements_dict[column] = element\n",
    "            \n",
    "        # Convert float columns to float32\n",
    "        for column in columns:\n",
    "            if df_grouped[column].dtype == 'float64':\n",
    "                df_grouped[column] = df_grouped[column].astype('float32')\n",
    "        \n",
    "        # Merge with the original DataFrame\n",
    "        df_combined = pd.merge(\n",
    "            df_combined, \n",
    "            df_grouped,\n",
    "            how='left', \n",
    "            on=groupby_columns\n",
    "        )\n",
    "    \n",
    "    # Update relationship_dict with elements_dict\n",
    "    relationship_dict.update(elements_dict)\n",
    "    \n",
    "    return df_combined, elements_dict\n",
    "\n",
    "df_combined, elements_dict = combine_sales_data(df_sales, elements, relationship_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Client</th>\n",
       "      <th>Warehouse</th>\n",
       "      <th>Product</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>total_sales_sum_by_client</th>\n",
       "      <th>total_sales_std_by_client</th>\n",
       "      <th>total_sales_mean_by_client</th>\n",
       "      <th>total_sales_median_by_client</th>\n",
       "      <th>total_sales_sum_by_warehouse</th>\n",
       "      <th>...</th>\n",
       "      <th>total_sales_mean_by_warehouse</th>\n",
       "      <th>total_sales_median_by_warehouse</th>\n",
       "      <th>total_sales_sum_by_product</th>\n",
       "      <th>total_sales_std_by_product</th>\n",
       "      <th>total_sales_mean_by_product</th>\n",
       "      <th>total_sales_median_by_product</th>\n",
       "      <th>total_sales_sum_by_date</th>\n",
       "      <th>total_sales_std_by_date</th>\n",
       "      <th>total_sales_mean_by_date</th>\n",
       "      <th>total_sales_median_by_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>367</td>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>7.0</td>\n",
       "      <td>46392.0</td>\n",
       "      <td>174.881729</td>\n",
       "      <td>49.883869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>53.265133</td>\n",
       "      <td>20.416666</td>\n",
       "      <td>7.0</td>\n",
       "      <td>105735.0</td>\n",
       "      <td>65.623100</td>\n",
       "      <td>7.024181</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>639</td>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46392.0</td>\n",
       "      <td>174.881729</td>\n",
       "      <td>49.883869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105735.0</td>\n",
       "      <td>65.623100</td>\n",
       "      <td>7.024181</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>655</td>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>21.0</td>\n",
       "      <td>46392.0</td>\n",
       "      <td>174.881729</td>\n",
       "      <td>49.883869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>910.0</td>\n",
       "      <td>209.894424</td>\n",
       "      <td>60.666668</td>\n",
       "      <td>7.0</td>\n",
       "      <td>105735.0</td>\n",
       "      <td>65.623100</td>\n",
       "      <td>7.024181</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1149</td>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>7.0</td>\n",
       "      <td>46392.0</td>\n",
       "      <td>174.881729</td>\n",
       "      <td>49.883869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>56.174728</td>\n",
       "      <td>22.400000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>105735.0</td>\n",
       "      <td>65.623100</td>\n",
       "      <td>7.024181</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1485</td>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46392.0</td>\n",
       "      <td>174.881729</td>\n",
       "      <td>49.883869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105735.0</td>\n",
       "      <td>65.623100</td>\n",
       "      <td>7.024181</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754694</th>\n",
       "      <td>46</td>\n",
       "      <td>318</td>\n",
       "      <td>13485</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2516.0</td>\n",
       "      <td>26.513712</td>\n",
       "      <td>10.752137</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1804.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.925373</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>248037.0</td>\n",
       "      <td>96.780884</td>\n",
       "      <td>16.477579</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754695</th>\n",
       "      <td>46</td>\n",
       "      <td>318</td>\n",
       "      <td>13582</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2516.0</td>\n",
       "      <td>26.513712</td>\n",
       "      <td>10.752137</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1804.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.925373</td>\n",
       "      <td>4.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>28.257742</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>248037.0</td>\n",
       "      <td>96.780884</td>\n",
       "      <td>16.477579</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754696</th>\n",
       "      <td>46</td>\n",
       "      <td>318</td>\n",
       "      <td>13691</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2516.0</td>\n",
       "      <td>26.513712</td>\n",
       "      <td>10.752137</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1804.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.925373</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>248037.0</td>\n",
       "      <td>96.780884</td>\n",
       "      <td>16.477579</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754697</th>\n",
       "      <td>46</td>\n",
       "      <td>318</td>\n",
       "      <td>13946</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2516.0</td>\n",
       "      <td>26.513712</td>\n",
       "      <td>10.752137</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1804.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.925373</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>248037.0</td>\n",
       "      <td>96.780884</td>\n",
       "      <td>16.477579</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754698</th>\n",
       "      <td>46</td>\n",
       "      <td>318</td>\n",
       "      <td>14294</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2516.0</td>\n",
       "      <td>26.513712</td>\n",
       "      <td>10.752137</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1804.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.925373</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.121320</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>248037.0</td>\n",
       "      <td>96.780884</td>\n",
       "      <td>16.477579</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2754699 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Client  Warehouse  Product       Date  Sales  \\\n",
       "0             0          1      367 2020-07-06    7.0   \n",
       "1             0          1      639 2020-07-06    0.0   \n",
       "2             0          1      655 2020-07-06   21.0   \n",
       "3             0          1     1149 2020-07-06    7.0   \n",
       "4             0          1     1485 2020-07-06    0.0   \n",
       "...         ...        ...      ...        ...    ...   \n",
       "2754694      46        318    13485 2024-01-01    0.0   \n",
       "2754695      46        318    13582 2024-01-01   67.0   \n",
       "2754696      46        318    13691 2024-01-01    2.0   \n",
       "2754697      46        318    13946 2024-01-01    0.0   \n",
       "2754698      46        318    14294 2024-01-01    3.0   \n",
       "\n",
       "         total_sales_sum_by_client  total_sales_std_by_client  \\\n",
       "0                          46392.0                 174.881729   \n",
       "1                          46392.0                 174.881729   \n",
       "2                          46392.0                 174.881729   \n",
       "3                          46392.0                 174.881729   \n",
       "4                          46392.0                 174.881729   \n",
       "...                            ...                        ...   \n",
       "2754694                     2516.0                  26.513712   \n",
       "2754695                     2516.0                  26.513712   \n",
       "2754696                     2516.0                  26.513712   \n",
       "2754697                     2516.0                  26.513712   \n",
       "2754698                     2516.0                  26.513712   \n",
       "\n",
       "         total_sales_mean_by_client  total_sales_median_by_client  \\\n",
       "0                         49.883869                           0.0   \n",
       "1                         49.883869                           0.0   \n",
       "2                         49.883869                           0.0   \n",
       "3                         49.883869                           0.0   \n",
       "4                         49.883869                           0.0   \n",
       "...                             ...                           ...   \n",
       "2754694                   10.752137                           1.0   \n",
       "2754695                   10.752137                           1.0   \n",
       "2754696                   10.752137                           1.0   \n",
       "2754697                   10.752137                           1.0   \n",
       "2754698                   10.752137                           1.0   \n",
       "\n",
       "         total_sales_sum_by_warehouse  ...  total_sales_mean_by_warehouse  \\\n",
       "0                               294.0  ...                       7.000000   \n",
       "1                               294.0  ...                       7.000000   \n",
       "2                               294.0  ...                       7.000000   \n",
       "3                               294.0  ...                       7.000000   \n",
       "4                               294.0  ...                       7.000000   \n",
       "...                               ...  ...                            ...   \n",
       "2754694                        1804.0  ...                      26.925373   \n",
       "2754695                        1804.0  ...                      26.925373   \n",
       "2754696                        1804.0  ...                      26.925373   \n",
       "2754697                        1804.0  ...                      26.925373   \n",
       "2754698                        1804.0  ...                      26.925373   \n",
       "\n",
       "         total_sales_median_by_warehouse  total_sales_sum_by_product  \\\n",
       "0                                    7.0                       245.0   \n",
       "1                                    7.0                         0.0   \n",
       "2                                    7.0                       910.0   \n",
       "3                                    7.0                       224.0   \n",
       "4                                    7.0                         0.0   \n",
       "...                                  ...                         ...   \n",
       "2754694                              4.0                         0.0   \n",
       "2754695                              4.0                        85.0   \n",
       "2754696                              4.0                         3.0   \n",
       "2754697                              4.0                         0.0   \n",
       "2754698                              4.0                         3.0   \n",
       "\n",
       "         total_sales_std_by_product  total_sales_mean_by_product  \\\n",
       "0                         53.265133                    20.416666   \n",
       "1                          0.000000                     0.000000   \n",
       "2                        209.894424                    60.666668   \n",
       "3                         56.174728                    22.400000   \n",
       "4                          0.000000                     0.000000   \n",
       "...                             ...                          ...   \n",
       "2754694                    0.000000                     0.000000   \n",
       "2754695                   28.257742                    17.000000   \n",
       "2754696                    0.707107                     1.500000   \n",
       "2754697                    0.000000                     0.000000   \n",
       "2754698                    2.121320                     1.500000   \n",
       "\n",
       "         total_sales_median_by_product  total_sales_sum_by_date  \\\n",
       "0                                  7.0                 105735.0   \n",
       "1                                  0.0                 105735.0   \n",
       "2                                  7.0                 105735.0   \n",
       "3                                  7.0                 105735.0   \n",
       "4                                  0.0                 105735.0   \n",
       "...                                ...                      ...   \n",
       "2754694                            0.0                 248037.0   \n",
       "2754695                            7.0                 248037.0   \n",
       "2754696                            1.5                 248037.0   \n",
       "2754697                            0.0                 248037.0   \n",
       "2754698                            1.5                 248037.0   \n",
       "\n",
       "         total_sales_std_by_date  total_sales_mean_by_date  \\\n",
       "0                      65.623100                  7.024181   \n",
       "1                      65.623100                  7.024181   \n",
       "2                      65.623100                  7.024181   \n",
       "3                      65.623100                  7.024181   \n",
       "4                      65.623100                  7.024181   \n",
       "...                          ...                       ...   \n",
       "2754694                96.780884                 16.477579   \n",
       "2754695                96.780884                 16.477579   \n",
       "2754696                96.780884                 16.477579   \n",
       "2754697                96.780884                 16.477579   \n",
       "2754698                96.780884                 16.477579   \n",
       "\n",
       "         total_sales_median_by_date  \n",
       "0                               0.0  \n",
       "1                               0.0  \n",
       "2                               0.0  \n",
       "3                               0.0  \n",
       "4                               0.0  \n",
       "...                             ...  \n",
       "2754694                         0.0  \n",
       "2754695                         0.0  \n",
       "2754696                         0.0  \n",
       "2754697                         0.0  \n",
       "2754698                         0.0  \n",
       "\n",
       "[2754699 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fill missing values with 0\n",
    "df_combined.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Week, Month and Year columns\n",
    "df_combined[\"Date\"] = pd.to_datetime(df_combined[\"Date\"])\n",
    "df_combined[\"Week\"] = df_combined[\"Date\"].dt.isocalendar().week\n",
    "df_combined[\"Month\"] = df_combined[\"Date\"].dt.month\n",
    "df_combined[\"Year\"] = df_combined[\"Date\"].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Lag Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagged_features = []\n",
    "\n",
    "def create_lagged_features(df, columns_to_lag, groupby_columns,simple_lags):\n",
    "    \"\"\"\n",
    "    Create lagged features and moving averages for specified columns in the DataFrame,\n",
    "    grouped by specified columns.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame.\n",
    "    columns_to_lag (list): List of column names to create lagged features and moving averages for.\n",
    "    groupby_columns (list): List of column names to group by.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with lagged features and moving averages added.\n",
    "    \"\"\"\n",
    "    new_columns = []\n",
    "\n",
    "    new_columns = []\n",
    "    grouped = df.groupby(groupby_columns)\n",
    "    \n",
    "    for col in columns_to_lag:\n",
    "        # Create lagged features\n",
    "        # print(col)\n",
    "        for lag in simple_lags:\n",
    "            lagged_col = f'{col}_lag_{lag}'\n",
    "            # lagged_col_rocp = f'{col}_lag_{lag}_rocp'\n",
    "            \n",
    "            df[lagged_col] = grouped[col].shift(lag)\n",
    "            # df[lagged_col_rocp] = np.log1p(grouped[col].shift(lag).pct_change())\n",
    "            \n",
    "            \n",
    "            new_columns.append(lagged_col)\n",
    "            \n",
    "        # Create moving averages, ROCP, moving standard deviations\n",
    "        # for window in [3, 5, 7, 9, 14, 20, 28]:\n",
    "        #     ma_col = f'{col}_ma_{window}'\n",
    "        #     rocp_col = f'{col}_ROCP_{window}'\n",
    "        #     std_col = f'{col}_std_{window}'\n",
    "        #     ema_col = f'{col}_ema_{window}'\n",
    "            \n",
    "        #     df[ma_col] = grouped[col].shift(1).rolling(window=window).mean()\n",
    "        #     df[rocp_col] = grouped[col].pct_change(periods=window).shift(1)\n",
    "        #     df[std_col] = grouped[col].shift(1).rolling(window=window).std()\n",
    "        #     df[ema_col] = grouped[col].shift(1).ewm(span=window, adjust=False).mean()\n",
    "            \n",
    "        #     new_columns.extend([ma_col, rocp_col, std_col])\n",
    "\n",
    "    \n",
    "    df = df.copy()\n",
    "    # Convert float columns to float32\n",
    "    for column in new_columns:\n",
    "        if df[column].dtype in [np.float64, np.float32]:\n",
    "            if df[column].dtype == np.float64 and df[column].max() < np.finfo(\"float16\").max:\n",
    "                df[column] = df[column].astype(\"float16\")\n",
    "            elif df[column].dtype == np.float64 and df[column].max() < np.finfo(\"float32\").max:\n",
    "                df[column] = df[column].astype(\"float32\")\n",
    "            elif df[column].dtype == np.float32 and df[column].max() < np.finfo(\"float16\").max:\n",
    "                df[column] = df[column].astype(\"float16\")\n",
    "    return df, new_columns\n",
    "\n",
    "\n",
    "columns_to_lag = [col for col in df_combined.columns if 'sales' in col.lower()]\n",
    "groupby_columns = [\"Client\", \"Warehouse\", \"Product\"]\n",
    "simple_lags = [i for i in range(1, 21)]\n",
    "df_combined, new_columns = create_lagged_features(df_combined, columns_to_lag, groupby_columns,simple_lags)\n",
    "lagged_features.extend(new_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Fourier terms\n",
    "# Define the number of Fourier terms\n",
    "num_terms = 13\n",
    "\n",
    "# Create Fourier terms\n",
    "for i in range(1, num_terms):  # Assuming n is defined somewhere in your code\n",
    "    df_combined[f'sin_{i}'] = np.sin(2 * np.pi * i * df_combined['Week'] / 52).astype('float16')\n",
    "    df_combined[f'cos_{i}'] = np.cos(2 * np.pi * i * df_combined['Week'] / 52).astype('float16')\n",
    "\n",
    "\n",
    "df_combined = df_combined.fillna(0)\n",
    "# Replace positive infinite values with 1 and negative infinite values with -1\n",
    "df_combined = df_combined.replace([np.inf, -np.inf], [1, -1])\n",
    "\n",
    "df_combined[\"product_week_warehouse\"] = pd.Categorical(df_combined[\"Product\"].astype(str) + \"/\" + df_combined[\"Week\"].astype(str) + \"/\" + df_combined[\"Warehouse\"].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Features to be used for Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the categorical features\n",
    "cat_features = ['Client', 'Warehouse', 'Product',\"Week\",\"Month\",\"Year\"]\n",
    "\n",
    "# Define the columns to drop from the training data\n",
    "columns_to_drop = [\"Date\", \"Sales\"] + list(relationship_dict.keys())\n",
    "\n",
    "# Get train columns\n",
    "train_columns = df_combined.drop(columns=columns_to_drop).columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train LGMB Model Using Tweedie Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda\\envs\\forecasting\\lib\\site-packages\\lightgbm\\engine.py:204: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.031516 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 84767\n",
      "[LightGBM] [Info] Number of data points in the train set: 2754699, number of used features: 351\n",
      "[LightGBM] [Info] Start training from score 2.580259\n"
     ]
    }
   ],
   "source": [
    "# Use the LightGBM model\n",
    "params = {\n",
    "    \"objective\": \"tweedie\",\n",
    "    \"metric\": \"rmse\",\n",
    "    \"verbose\": 1,\n",
    "    \"num_iterations\": 100,\n",
    "    \"num_leaves\": 256,\n",
    "    \"learning_rate\": 0.2,\n",
    "    \"tweedie_variance_power\": 1.1,\n",
    "}\n",
    "\n",
    "# Dictionary to store evaluation results\n",
    "evals_result = {}\n",
    "\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    lgb.Dataset(\n",
    "        df_combined[train_columns],\n",
    "        label=df_combined[\"Sales\"],\n",
    "        categorical_feature=cat_features,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Product', 51.61),\n",
       " ('Week', 11.21),\n",
       " ('Warehouse', 6.93),\n",
       " ('Sales_lag_1', 1.55),\n",
       " ('Sales_lag_2', 1.05),\n",
       " ('Sales_lag_3', 0.67),\n",
       " ('Sales_lag_4', 0.59),\n",
       " ('total_sales_mean_by_warehouse_lag_1', 0.47),\n",
       " ('Client', 0.4),\n",
       " ('Sales_lag_5', 0.39),\n",
       " ('total_sales_sum_by_warehouse_lag_1', 0.34),\n",
       " ('total_sales_sum_by_date_lag_1', 0.34),\n",
       " ('Sales_lag_6', 0.29),\n",
       " ('total_sales_sum_by_client_lag_1', 0.29),\n",
       " ('total_sales_std_by_warehouse_lag_1', 0.29),\n",
       " ('total_sales_sum_by_product_lag_1', 0.29),\n",
       " ('Sales_lag_7', 0.27),\n",
       " ('Sales_lag_17', 0.25),\n",
       " ('total_sales_median_by_warehouse_lag_1', 0.25),\n",
       " ('Sales_lag_13', 0.24),\n",
       " ('total_sales_sum_by_product_lag_2', 0.24),\n",
       " ('total_sales_mean_by_product_lag_1', 0.24),\n",
       " ('Sales_lag_8', 0.23),\n",
       " ('Sales_lag_9', 0.23),\n",
       " ('total_sales_sum_by_client_lag_4', 0.22),\n",
       " ('total_sales_sum_by_client_lag_6', 0.22),\n",
       " ('total_sales_sum_by_client_lag_2', 0.21),\n",
       " ('total_sales_sum_by_product_lag_4', 0.21),\n",
       " ('Sales_lag_18', 0.2),\n",
       " ('total_sales_std_by_client_lag_1', 0.19),\n",
       " ('Sales_lag_10', 0.18),\n",
       " ('Sales_lag_12', 0.18),\n",
       " ('total_sales_sum_by_product_lag_3', 0.17),\n",
       " ('Sales_lag_15', 0.15),\n",
       " ('Sales_lag_16', 0.15),\n",
       " ('total_sales_mean_by_client_lag_1', 0.15),\n",
       " ('total_sales_sum_by_warehouse_lag_2', 0.15),\n",
       " ('total_sales_mean_by_product_lag_2', 0.15),\n",
       " ('total_sales_std_by_date_lag_1', 0.15),\n",
       " ('total_sales_sum_by_client_lag_3', 0.14),\n",
       " ('total_sales_std_by_product_lag_1', 0.14),\n",
       " ('Sales_lag_19', 0.13),\n",
       " ('Sales_lag_20', 0.13),\n",
       " ('total_sales_sum_by_client_lag_11', 0.13),\n",
       " ('total_sales_sum_by_warehouse_lag_3', 0.13),\n",
       " ('total_sales_sum_by_warehouse_lag_4', 0.13),\n",
       " ('total_sales_sum_by_warehouse_lag_5', 0.13),\n",
       " ('total_sales_median_by_warehouse_lag_11', 0.13),\n",
       " ('total_sales_sum_by_product_lag_5', 0.13),\n",
       " ('total_sales_sum_by_date_lag_2', 0.13),\n",
       " ('total_sales_std_by_date_lag_2', 0.13),\n",
       " ('total_sales_std_by_date_lag_19', 0.13),\n",
       " ('total_sales_sum_by_client_lag_5', 0.12),\n",
       " ('total_sales_sum_by_client_lag_10', 0.12),\n",
       " ('total_sales_std_by_client_lag_7', 0.12),\n",
       " ('total_sales_sum_by_product_lag_6', 0.12),\n",
       " ('total_sales_std_by_date_lag_3', 0.12),\n",
       " ('total_sales_std_by_date_lag_7', 0.12),\n",
       " ('Sales_lag_11', 0.11),\n",
       " ('total_sales_sum_by_client_lag_8', 0.11),\n",
       " ('total_sales_sum_by_client_lag_19', 0.11),\n",
       " ('total_sales_sum_by_warehouse_lag_9', 0.11),\n",
       " ('total_sales_std_by_warehouse_lag_3', 0.11),\n",
       " ('total_sales_median_by_warehouse_lag_2', 0.11),\n",
       " ('total_sales_mean_by_product_lag_3', 0.11),\n",
       " ('total_sales_median_by_product_lag_4', 0.11),\n",
       " ('total_sales_sum_by_date_lag_5', 0.11),\n",
       " ('total_sales_std_by_date_lag_4', 0.11),\n",
       " ('total_sales_std_by_date_lag_17', 0.11),\n",
       " ('Month', 0.1),\n",
       " ('total_sales_sum_by_client_lag_7', 0.1),\n",
       " ('total_sales_sum_by_client_lag_9', 0.1),\n",
       " ('total_sales_std_by_client_lag_5', 0.1),\n",
       " ('total_sales_std_by_client_lag_12', 0.1),\n",
       " ('total_sales_std_by_warehouse_lag_2', 0.1),\n",
       " ('total_sales_std_by_warehouse_lag_4', 0.1),\n",
       " ('total_sales_std_by_warehouse_lag_8', 0.1),\n",
       " ('total_sales_mean_by_warehouse_lag_3', 0.1),\n",
       " ('total_sales_mean_by_warehouse_lag_4', 0.1),\n",
       " ('total_sales_sum_by_product_lag_7', 0.1),\n",
       " ('total_sales_mean_by_product_lag_4', 0.1),\n",
       " ('total_sales_median_by_product_lag_1', 0.1),\n",
       " ('total_sales_sum_by_date_lag_3', 0.1),\n",
       " ('total_sales_sum_by_date_lag_19', 0.1),\n",
       " ('total_sales_std_by_date_lag_6', 0.1),\n",
       " ('total_sales_std_by_date_lag_8', 0.1),\n",
       " ('total_sales_std_by_date_lag_13', 0.1),\n",
       " ('Sales_lag_14', 0.09),\n",
       " ('total_sales_sum_by_client_lag_12', 0.09),\n",
       " ('total_sales_sum_by_client_lag_17', 0.09),\n",
       " ('total_sales_sum_by_client_lag_20', 0.09),\n",
       " ('total_sales_std_by_client_lag_2', 0.09),\n",
       " ('total_sales_std_by_client_lag_4', 0.09),\n",
       " ('total_sales_sum_by_warehouse_lag_6', 0.09),\n",
       " ('total_sales_sum_by_warehouse_lag_7', 0.09),\n",
       " ('total_sales_sum_by_warehouse_lag_20', 0.09),\n",
       " ('total_sales_std_by_warehouse_lag_6', 0.09),\n",
       " ('total_sales_std_by_warehouse_lag_7', 0.09),\n",
       " ('total_sales_std_by_warehouse_lag_14', 0.09),\n",
       " ('total_sales_median_by_warehouse_lag_7', 0.09),\n",
       " ('total_sales_sum_by_product_lag_17', 0.09),\n",
       " ('total_sales_std_by_product_lag_2', 0.09),\n",
       " ('total_sales_mean_by_product_lag_5', 0.09),\n",
       " ('total_sales_median_by_product_lag_2', 0.09),\n",
       " ('total_sales_sum_by_date_lag_4', 0.09),\n",
       " ('total_sales_sum_by_date_lag_10', 0.09),\n",
       " ('total_sales_std_by_date_lag_10', 0.09),\n",
       " ('total_sales_std_by_date_lag_11', 0.09),\n",
       " ('total_sales_std_by_date_lag_20', 0.09),\n",
       " ('total_sales_sum_by_client_lag_13', 0.08),\n",
       " ('total_sales_sum_by_client_lag_14', 0.08),\n",
       " ('total_sales_std_by_client_lag_3', 0.08),\n",
       " ('total_sales_std_by_client_lag_6', 0.08),\n",
       " ('total_sales_std_by_client_lag_8', 0.08),\n",
       " ('total_sales_std_by_client_lag_14', 0.08),\n",
       " ('total_sales_mean_by_client_lag_3', 0.08),\n",
       " ('total_sales_sum_by_warehouse_lag_11', 0.08),\n",
       " ('total_sales_sum_by_warehouse_lag_19', 0.08),\n",
       " ('total_sales_std_by_warehouse_lag_10', 0.08),\n",
       " ('total_sales_std_by_warehouse_lag_11', 0.08),\n",
       " ('total_sales_std_by_warehouse_lag_13', 0.08),\n",
       " ('total_sales_std_by_warehouse_lag_19', 0.08),\n",
       " ('total_sales_mean_by_warehouse_lag_2', 0.08),\n",
       " ('total_sales_median_by_warehouse_lag_4', 0.08),\n",
       " ('total_sales_median_by_warehouse_lag_18', 0.08),\n",
       " ('total_sales_median_by_warehouse_lag_20', 0.08),\n",
       " ('total_sales_sum_by_product_lag_10', 0.08),\n",
       " ('total_sales_sum_by_product_lag_13', 0.08),\n",
       " ('total_sales_std_by_product_lag_3', 0.08),\n",
       " ('total_sales_mean_by_product_lag_6', 0.08),\n",
       " ('total_sales_median_by_product_lag_20', 0.08),\n",
       " ('total_sales_sum_by_date_lag_7', 0.08),\n",
       " ('total_sales_std_by_date_lag_12', 0.08),\n",
       " ('total_sales_std_by_date_lag_16', 0.08),\n",
       " ('total_sales_std_by_client_lag_13', 0.07),\n",
       " ('total_sales_std_by_client_lag_19', 0.07),\n",
       " ('total_sales_std_by_client_lag_20', 0.07),\n",
       " ('total_sales_mean_by_client_lag_2', 0.07),\n",
       " ('total_sales_mean_by_client_lag_4', 0.07),\n",
       " ('total_sales_mean_by_client_lag_8', 0.07),\n",
       " ('total_sales_mean_by_client_lag_20', 0.07),\n",
       " ('total_sales_median_by_client_lag_1', 0.07),\n",
       " ('total_sales_median_by_client_lag_2', 0.07),\n",
       " ('total_sales_sum_by_warehouse_lag_8', 0.07),\n",
       " ('total_sales_sum_by_warehouse_lag_12', 0.07),\n",
       " ('total_sales_sum_by_warehouse_lag_16', 0.07),\n",
       " ('total_sales_sum_by_warehouse_lag_17', 0.07),\n",
       " ('total_sales_std_by_warehouse_lag_5', 0.07),\n",
       " ('total_sales_std_by_warehouse_lag_15', 0.07),\n",
       " ('total_sales_std_by_warehouse_lag_16', 0.07),\n",
       " ('total_sales_mean_by_warehouse_lag_5', 0.07),\n",
       " ('total_sales_median_by_warehouse_lag_5', 0.07),\n",
       " ('total_sales_median_by_warehouse_lag_8', 0.07),\n",
       " ('total_sales_median_by_warehouse_lag_9', 0.07),\n",
       " ('total_sales_median_by_warehouse_lag_10', 0.07),\n",
       " ('total_sales_median_by_warehouse_lag_13', 0.07),\n",
       " ('total_sales_median_by_warehouse_lag_15', 0.07),\n",
       " ('total_sales_median_by_warehouse_lag_17', 0.07),\n",
       " ('total_sales_median_by_warehouse_lag_19', 0.07),\n",
       " ('total_sales_sum_by_product_lag_9', 0.07),\n",
       " ('total_sales_sum_by_product_lag_12', 0.07),\n",
       " ('total_sales_sum_by_product_lag_18', 0.07),\n",
       " ('total_sales_sum_by_product_lag_20', 0.07),\n",
       " ('total_sales_mean_by_product_lag_8', 0.07),\n",
       " ('total_sales_mean_by_product_lag_10', 0.07),\n",
       " ('total_sales_mean_by_product_lag_20', 0.07),\n",
       " ('total_sales_median_by_product_lag_3', 0.07),\n",
       " ('total_sales_median_by_product_lag_10', 0.07),\n",
       " ('total_sales_median_by_product_lag_13', 0.07),\n",
       " ('total_sales_median_by_product_lag_17', 0.07),\n",
       " ('total_sales_sum_by_date_lag_8', 0.07),\n",
       " ('total_sales_sum_by_date_lag_9', 0.07),\n",
       " ('total_sales_sum_by_date_lag_11', 0.07),\n",
       " ('total_sales_sum_by_date_lag_18', 0.07),\n",
       " ('total_sales_std_by_date_lag_5', 0.07),\n",
       " ('total_sales_std_by_date_lag_9', 0.07),\n",
       " ('total_sales_std_by_date_lag_14', 0.07),\n",
       " ('total_sales_std_by_date_lag_15', 0.07),\n",
       " ('total_sales_std_by_date_lag_18', 0.07),\n",
       " ('cos_1', 0.07),\n",
       " ('total_sales_sum_by_client_lag_15', 0.06),\n",
       " ('total_sales_sum_by_client_lag_16', 0.06),\n",
       " ('total_sales_std_by_client_lag_9', 0.06),\n",
       " ('total_sales_std_by_client_lag_11', 0.06),\n",
       " ('total_sales_std_by_client_lag_17', 0.06),\n",
       " ('total_sales_mean_by_client_lag_6', 0.06),\n",
       " ('total_sales_sum_by_warehouse_lag_18', 0.06),\n",
       " ('total_sales_std_by_warehouse_lag_9', 0.06),\n",
       " ('total_sales_std_by_warehouse_lag_12', 0.06),\n",
       " ('total_sales_mean_by_warehouse_lag_7', 0.06),\n",
       " ('total_sales_mean_by_warehouse_lag_8', 0.06),\n",
       " ('total_sales_mean_by_warehouse_lag_18', 0.06),\n",
       " ('total_sales_median_by_warehouse_lag_3', 0.06),\n",
       " ('total_sales_median_by_warehouse_lag_12', 0.06),\n",
       " ('total_sales_sum_by_product_lag_8', 0.06),\n",
       " ('total_sales_sum_by_product_lag_16', 0.06),\n",
       " ('total_sales_mean_by_product_lag_12', 0.06),\n",
       " ('total_sales_mean_by_product_lag_14', 0.06),\n",
       " ('total_sales_median_by_product_lag_7', 0.06),\n",
       " ('total_sales_median_by_product_lag_11', 0.06),\n",
       " ('total_sales_median_by_product_lag_16', 0.06),\n",
       " ('total_sales_sum_by_date_lag_6', 0.06),\n",
       " ('product_week_warehouse', 0.06),\n",
       " ('total_sales_sum_by_client_lag_18', 0.05),\n",
       " ('total_sales_std_by_client_lag_10', 0.05),\n",
       " ('total_sales_std_by_client_lag_15', 0.05),\n",
       " ('total_sales_std_by_client_lag_16', 0.05),\n",
       " ('total_sales_mean_by_client_lag_5', 0.05),\n",
       " ('total_sales_mean_by_client_lag_7', 0.05),\n",
       " ('total_sales_mean_by_client_lag_9', 0.05),\n",
       " ('total_sales_mean_by_client_lag_11', 0.05),\n",
       " ('total_sales_mean_by_client_lag_13', 0.05),\n",
       " ('total_sales_sum_by_warehouse_lag_10', 0.05),\n",
       " ('total_sales_sum_by_warehouse_lag_14', 0.05),\n",
       " ('total_sales_std_by_warehouse_lag_17', 0.05),\n",
       " ('total_sales_std_by_warehouse_lag_18', 0.05),\n",
       " ('total_sales_mean_by_warehouse_lag_6', 0.05),\n",
       " ('total_sales_mean_by_warehouse_lag_10', 0.05),\n",
       " ('total_sales_mean_by_warehouse_lag_11', 0.05),\n",
       " ('total_sales_mean_by_warehouse_lag_14', 0.05),\n",
       " ('total_sales_mean_by_warehouse_lag_20', 0.05),\n",
       " ('total_sales_median_by_warehouse_lag_6', 0.05),\n",
       " ('total_sales_median_by_warehouse_lag_14', 0.05),\n",
       " ('total_sales_sum_by_product_lag_11', 0.05),\n",
       " ('total_sales_sum_by_product_lag_14', 0.05),\n",
       " ('total_sales_sum_by_product_lag_19', 0.05),\n",
       " ('total_sales_std_by_product_lag_4', 0.05),\n",
       " ('total_sales_std_by_product_lag_14', 0.05),\n",
       " ('total_sales_mean_by_product_lag_7', 0.05),\n",
       " ('total_sales_mean_by_product_lag_9', 0.05),\n",
       " ('total_sales_mean_by_product_lag_11', 0.05),\n",
       " ('total_sales_mean_by_product_lag_13', 0.05),\n",
       " ('total_sales_mean_by_product_lag_18', 0.05),\n",
       " ('total_sales_mean_by_product_lag_19', 0.05),\n",
       " ('total_sales_median_by_product_lag_6', 0.05),\n",
       " ('total_sales_median_by_product_lag_8', 0.05),\n",
       " ('total_sales_median_by_product_lag_14', 0.05),\n",
       " ('total_sales_median_by_product_lag_15', 0.05),\n",
       " ('total_sales_median_by_product_lag_18', 0.05),\n",
       " ('total_sales_sum_by_date_lag_12', 0.05),\n",
       " ('total_sales_sum_by_date_lag_14', 0.05),\n",
       " ('total_sales_sum_by_date_lag_16', 0.05),\n",
       " ('total_sales_sum_by_date_lag_17', 0.05),\n",
       " ('total_sales_sum_by_date_lag_20', 0.05),\n",
       " ('sin_3', 0.05),\n",
       " ('sin_7', 0.05),\n",
       " ('total_sales_std_by_client_lag_18', 0.04),\n",
       " ('total_sales_mean_by_client_lag_12', 0.04),\n",
       " ('total_sales_mean_by_client_lag_14', 0.04),\n",
       " ('total_sales_mean_by_client_lag_17', 0.04),\n",
       " ('total_sales_mean_by_client_lag_18', 0.04),\n",
       " ('total_sales_mean_by_client_lag_19', 0.04),\n",
       " ('total_sales_median_by_client_lag_4', 0.04),\n",
       " ('total_sales_sum_by_warehouse_lag_13', 0.04),\n",
       " ('total_sales_sum_by_warehouse_lag_15', 0.04),\n",
       " ('total_sales_std_by_warehouse_lag_20', 0.04),\n",
       " ('total_sales_mean_by_warehouse_lag_9', 0.04),\n",
       " ('total_sales_mean_by_warehouse_lag_12', 0.04),\n",
       " ('total_sales_mean_by_warehouse_lag_13', 0.04),\n",
       " ('total_sales_mean_by_warehouse_lag_15', 0.04),\n",
       " ('total_sales_mean_by_warehouse_lag_19', 0.04),\n",
       " ('total_sales_median_by_warehouse_lag_16', 0.04),\n",
       " ('total_sales_sum_by_product_lag_15', 0.04),\n",
       " ('total_sales_std_by_product_lag_5', 0.04),\n",
       " ('total_sales_std_by_product_lag_7', 0.04),\n",
       " ('total_sales_std_by_product_lag_11', 0.04),\n",
       " ('total_sales_std_by_product_lag_13', 0.04),\n",
       " ('total_sales_std_by_product_lag_15', 0.04),\n",
       " ('total_sales_std_by_product_lag_17', 0.04),\n",
       " ('total_sales_std_by_product_lag_18', 0.04),\n",
       " ('total_sales_std_by_product_lag_19', 0.04),\n",
       " ('total_sales_median_by_product_lag_5', 0.04),\n",
       " ('total_sales_median_by_product_lag_9', 0.04),\n",
       " ('total_sales_median_by_product_lag_12', 0.04),\n",
       " ('total_sales_sum_by_date_lag_13', 0.04),\n",
       " ('total_sales_sum_by_date_lag_15', 0.04),\n",
       " ('sin_1', 0.04),\n",
       " ('cos_3', 0.04),\n",
       " ('cos_7', 0.04),\n",
       " ('sin_8', 0.04),\n",
       " ('cos_9', 0.04),\n",
       " ('Year', 0.03),\n",
       " ('total_sales_mean_by_client_lag_15', 0.03),\n",
       " ('total_sales_median_by_client_lag_3', 0.03),\n",
       " ('total_sales_median_by_client_lag_5', 0.03),\n",
       " ('total_sales_median_by_client_lag_19', 0.03),\n",
       " ('total_sales_mean_by_warehouse_lag_16', 0.03),\n",
       " ('total_sales_mean_by_warehouse_lag_17', 0.03),\n",
       " ('total_sales_std_by_product_lag_6', 0.03),\n",
       " ('total_sales_std_by_product_lag_8', 0.03),\n",
       " ('total_sales_std_by_product_lag_20', 0.03),\n",
       " ('total_sales_mean_by_product_lag_16', 0.03),\n",
       " ('total_sales_mean_by_product_lag_17', 0.03),\n",
       " ('total_sales_median_by_product_lag_19', 0.03),\n",
       " ('sin_2', 0.03),\n",
       " ('total_sales_mean_by_client_lag_10', 0.02),\n",
       " ('total_sales_mean_by_client_lag_16', 0.02),\n",
       " ('total_sales_median_by_client_lag_7', 0.02),\n",
       " ('total_sales_median_by_client_lag_9', 0.02),\n",
       " ('total_sales_median_by_client_lag_10', 0.02),\n",
       " ('total_sales_median_by_client_lag_13', 0.02),\n",
       " ('total_sales_median_by_client_lag_14', 0.02),\n",
       " ('total_sales_std_by_product_lag_9', 0.02),\n",
       " ('total_sales_std_by_product_lag_10', 0.02),\n",
       " ('total_sales_std_by_product_lag_12', 0.02),\n",
       " ('total_sales_std_by_product_lag_16', 0.02),\n",
       " ('total_sales_mean_by_product_lag_15', 0.02),\n",
       " ('cos_2', 0.02),\n",
       " ('sin_4', 0.02),\n",
       " ('cos_4', 0.02),\n",
       " ('cos_5', 0.02),\n",
       " ('cos_8', 0.02),\n",
       " ('sin_9', 0.02),\n",
       " ('sin_10', 0.02),\n",
       " ('cos_10', 0.02),\n",
       " ('sin_11', 0.02),\n",
       " ('cos_11', 0.02),\n",
       " ('sin_12', 0.02),\n",
       " ('cos_12', 0.02),\n",
       " ('total_sales_median_by_client_lag_6', 0.01),\n",
       " ('total_sales_median_by_client_lag_8', 0.01),\n",
       " ('total_sales_median_by_client_lag_11', 0.01),\n",
       " ('total_sales_median_by_client_lag_15', 0.01),\n",
       " ('total_sales_median_by_client_lag_16', 0.01),\n",
       " ('total_sales_median_by_client_lag_17', 0.01),\n",
       " ('total_sales_median_by_client_lag_18', 0.01),\n",
       " ('total_sales_median_by_client_lag_20', 0.01),\n",
       " ('sin_5', 0.01),\n",
       " ('cos_6', 0.01),\n",
       " ('total_sales_median_by_client_lag_12', 0.0),\n",
       " ('total_sales_mean_by_date_lag_1', 0.0),\n",
       " ('total_sales_mean_by_date_lag_2', 0.0),\n",
       " ('total_sales_mean_by_date_lag_3', 0.0),\n",
       " ('total_sales_mean_by_date_lag_4', 0.0),\n",
       " ('total_sales_mean_by_date_lag_5', 0.0),\n",
       " ('total_sales_mean_by_date_lag_6', 0.0),\n",
       " ('total_sales_mean_by_date_lag_7', 0.0),\n",
       " ('total_sales_mean_by_date_lag_8', 0.0),\n",
       " ('total_sales_mean_by_date_lag_9', 0.0),\n",
       " ('total_sales_mean_by_date_lag_10', 0.0),\n",
       " ('total_sales_mean_by_date_lag_11', 0.0),\n",
       " ('total_sales_mean_by_date_lag_12', 0.0),\n",
       " ('total_sales_mean_by_date_lag_13', 0.0),\n",
       " ('total_sales_mean_by_date_lag_14', 0.0),\n",
       " ('total_sales_mean_by_date_lag_15', 0.0),\n",
       " ('total_sales_mean_by_date_lag_16', 0.0),\n",
       " ('total_sales_mean_by_date_lag_17', 0.0),\n",
       " ('total_sales_mean_by_date_lag_18', 0.0),\n",
       " ('total_sales_mean_by_date_lag_19', 0.0),\n",
       " ('total_sales_mean_by_date_lag_20', 0.0),\n",
       " ('total_sales_median_by_date_lag_1', 0.0),\n",
       " ('total_sales_median_by_date_lag_2', 0.0),\n",
       " ('total_sales_median_by_date_lag_3', 0.0),\n",
       " ('total_sales_median_by_date_lag_4', 0.0),\n",
       " ('total_sales_median_by_date_lag_5', 0.0),\n",
       " ('total_sales_median_by_date_lag_6', 0.0),\n",
       " ('total_sales_median_by_date_lag_7', 0.0),\n",
       " ('total_sales_median_by_date_lag_8', 0.0),\n",
       " ('total_sales_median_by_date_lag_9', 0.0),\n",
       " ('total_sales_median_by_date_lag_10', 0.0),\n",
       " ('total_sales_median_by_date_lag_11', 0.0),\n",
       " ('total_sales_median_by_date_lag_12', 0.0),\n",
       " ('total_sales_median_by_date_lag_13', 0.0),\n",
       " ('total_sales_median_by_date_lag_14', 0.0),\n",
       " ('total_sales_median_by_date_lag_15', 0.0),\n",
       " ('total_sales_median_by_date_lag_16', 0.0),\n",
       " ('total_sales_median_by_date_lag_17', 0.0),\n",
       " ('total_sales_median_by_date_lag_18', 0.0),\n",
       " ('total_sales_median_by_date_lag_19', 0.0),\n",
       " ('total_sales_median_by_date_lag_20', 0.0),\n",
       " ('sin_6', 0.0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = model.feature_importance(importance_type='split')\n",
    "normalized_importances = (importances / importances.sum()) * 100\n",
    "normalized_importances = normalized_importances.round(2)\n",
    "list(sorted(zip(df_combined[train_columns].columns, normalized_importances), key=lambda xx: xx[1], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the submission by using **recursive forecasting**. This process involves forecasting the next week sales and using these values to predict the demand in the following time period. This process is repeated for 13 weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizons = {}\n",
    "predictions_dict = {}\n",
    "# Create 13 week horizon\n",
    "for i in range(1, 14):\n",
    "    horizons[i] = (df_combined[\"Date\"].max() + pd.DateOffset(7*i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: Timestamp('2024-01-08 00:00:00'),\n",
       " 2: Timestamp('2024-01-15 00:00:00'),\n",
       " 3: Timestamp('2024-01-22 00:00:00'),\n",
       " 4: Timestamp('2024-01-29 00:00:00'),\n",
       " 5: Timestamp('2024-02-05 00:00:00'),\n",
       " 6: Timestamp('2024-02-12 00:00:00'),\n",
       " 7: Timestamp('2024-02-19 00:00:00'),\n",
       " 8: Timestamp('2024-02-26 00:00:00'),\n",
       " 9: Timestamp('2024-03-04 00:00:00'),\n",
       " 10: Timestamp('2024-03-11 00:00:00'),\n",
       " 11: Timestamp('2024-03-18 00:00:00'),\n",
       " 12: Timestamp('2024-03-25 00:00:00'),\n",
       " 13: Timestamp('2024-04-01 00:00:00')}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to convert to object data type\n",
    "convert_obj = ['Client', 'Warehouse', 'Product',\"Sales\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-08 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/13 [00:09<01:57,  9.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-15 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 2/13 [00:19<01:46,  9.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-22 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 3/13 [00:28<01:34,  9.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-29 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 4/13 [00:39<01:29,  9.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-05 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 5/13 [00:48<01:17,  9.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-12 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 6/13 [00:57<01:07,  9.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-19 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 7/13 [01:07<00:56,  9.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-26 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 8/13 [01:16<00:47,  9.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-04 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 9/13 [01:25<00:37,  9.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-11 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 10/13 [01:35<00:28,  9.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-18 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 11/13 [01:44<00:18,  9.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-25 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 12/13 [01:53<00:09,  9.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [02:03<00:00,  9.47s/it]\n"
     ]
    }
   ],
   "source": [
    "for time_window in tq.tqdm(horizons):\n",
    "    print(horizons[time_window])\n",
    "    \n",
    "    # Take only the base data\n",
    "    df_combined = df_combined[[\"Client\", \"Warehouse\", \"Product\", \"Date\", \"Sales\"]]\n",
    "    \n",
    "    # Get Max 30 weeks before the horizon this speeds up the process immensely\n",
    "    firts_date = horizons[time_window] - pd.DateOffset(weeks=30)\n",
    "    df_combined = df_combined[(df_combined[\"Date\"] >= firts_date) & (df_combined[\"Date\"] <= horizons[time_window])]\n",
    "    \n",
    "    # Create the new time window and add it to the data\n",
    "    df_cwp = df_combined[['Client', 'Warehouse', 'Product']].drop_duplicates().sort_values(by=['Client', 'Warehouse', 'Product'])\n",
    "    df_cwp[\"Sales\"] = 0\n",
    "    df_cwp[\"Date\"] = horizons[time_window]\n",
    "    df_combined = pd.concat([df_combined, df_cwp], ignore_index=True)\n",
    "    \n",
    "    # Convert the columns to the specified data types\n",
    "    for col in convert_obj:\n",
    "        df_combined[col] = df_combined[col].astype(\"int32\")\n",
    "    \n",
    "    # Combine sales data by client, warehouse, product and date    \n",
    "    df_combined, elements_dict = combine_sales_data(df_combined, elements, relationship_dict)\n",
    "    df_combined = df_combined.fillna(0)\n",
    "    \n",
    "    # Create lagged features\n",
    "    df_combined, new_columns = create_lagged_features(df_combined, columns_to_lag, groupby_columns,simple_lags)\n",
    "\n",
    "    # Create Date features\n",
    "    df_combined[\"Date\"] = pd.to_datetime(df_combined[\"Date\"])\n",
    "    df_combined[\"Week\"] = df_combined[\"Date\"].dt.isocalendar().week\n",
    "    df_combined[\"Month\"] = df_combined[\"Date\"].dt.month\n",
    "    df_combined[\"Year\"] = df_combined[\"Date\"].dt.year\n",
    "    \n",
    "    df_combined[\"product_week_warehouse\"] = pd.Categorical(df_combined[\"Product\"].astype(str) + \"/\" + df_combined[\"Week\"].astype(str) + \"/\" + df_combined[\"Warehouse\"].astype(str))\n",
    "    \n",
    "\n",
    "    # Create Fourier terms\n",
    "    for i in range(1, num_terms):  # Assuming n is defined somewhere in your code\n",
    "        df_combined[f'sin_{i}'] = np.sin(2 * np.pi * i * df_combined['Week'] / 52).astype('float16')\n",
    "        df_combined[f'cos_{i}'] = np.cos(2 * np.pi * i * df_combined['Week'] / 52).astype('float16')\n",
    "        \n",
    "    # Predict the sales for the time window set all negative values to 0\n",
    "    y_pred = model.predict(df_combined[train_columns][df_combined.Date == horizons[time_window]])\n",
    "    y_pred = np.where(y_pred < 0, 0, y_pred)\n",
    "    submission = y_pred\n",
    "    \n",
    "    # Store the predictions in the dictionary and update the combined DataFrame\n",
    "    predictions_dict[horizons[time_window]] = submission\n",
    "    df_combined.loc[df_combined.Date == horizons[time_window], \"Sales\"] = submission\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get only the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 145.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_cwp = df_combined[['Client', 'Warehouse', 'Product']].drop_duplicates().sort_values(by=['Client', 'Warehouse', 'Product'])\n",
    "df_cwpd = pd.DataFrame(columns=[\"Client\", \"Warehouse\", \"Product\", \"Date\", \"Sales\"])\n",
    "\n",
    "for time_window in tq.tqdm(horizons):\n",
    "    print(time_window)\n",
    "    # dates_list = []\n",
    "    df_cwp[\"Date\"] = horizons[time_window]\n",
    "    df_cwp[\"Sales\"] = predictions_dict[horizons[time_window]]\n",
    "    df_cwpd = pd.concat([df_cwpd, df_cwp], ignore_index=True)\n",
    "df_cwpd[\"Sales\"] = df_cwpd[\"Sales\"].round()\n",
    "df_cwpd[\"Date\"] = pd.to_datetime(df_cwpd[\"Date\"]).dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the submission file in the required format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_df = df_cwpd.pivot(index=['Client', 'Warehouse', 'Product'], columns='Date', values='Sales').reset_index()\n",
    "pivoted_df.columns.name = None\n",
    "### Save to csv\n",
    "pivoted_df.to_csv(\"Submission_Phase_2_Teodor_Georgiev.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if my old submission is equal to the submission generated here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivoted_df_old = pd.read_csv(\"Submission_Phase_2.csv\")\n",
    "# pivoted_df_new = pd.read_csv(\"Submission_Phase_2_Teodor_Georgiev.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames are equal: True\n"
     ]
    }
   ],
   "source": [
    "# are_equal = pivoted_df_old.equals(pivoted_df_new)\n",
    "# print(\"DataFrames are equal:\", are_equal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
